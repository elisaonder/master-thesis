{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sampling Procedure for Manual Labeling\n",
        "In this notebook, a random sample of the previously created ParlaMint_PT_interventions. The ParlaMint_PT_interventions created during preprocessing stage contains a total of 248577 interventions. This random sample for manual labeling should include 1500."
      ],
      "metadata": {
        "id": "bD4WZlm0oooH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yY3WpRXkSZOF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import the data"
      ],
      "metadata": {
        "id": "j03Pe2zeCDD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#connect to google drive\n",
        "drive_path = '/content/drive/MyDrive/Thesis/ParlaMint_PT_interventions.csv'\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "print(\"Google Drive successfully accessed.\")\n",
        "\n",
        "#Import the data from google drive\n",
        "print(f\"Reading data from: {drive_path}\")\n",
        "try:\n",
        "    df_raw = pd.read_csv(drive_path, encoding='utf-8')\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: File not found at {drive_path}. Please check your path and filename.\")\n",
        "except UnicodeDecodeError:\n",
        "    print(\"UTF-8 decoding failed. Trying 'latin1' encoding...\")\n",
        "    df_raw = pd.read_csv(drive_path, encoding='latin1')\n",
        "\n",
        "print(f\"Interventions full dataset size: {len(df_raw)}\")\n",
        "\n",
        "# Clean up column names by removing spaces and converting to lowercase\n",
        "df_raw.columns = df_raw.columns.str.strip().str.lower()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cXWzeftT4pj",
        "outputId": "ea5a403b-ccba-4721-d0d9-5f70db9a6d56"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive successfully accessed.\n",
            "Reading data from: /content/drive/MyDrive/Thesis/ParlaMint_PT_interventions.csv\n",
            "Interventions full dataset size: 248577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Sampling for Manual Labeling and create an empty column for manual labeling"
      ],
      "metadata": {
        "id": "y0Dvcb2TCmrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Intervention_sample_size = 1500\n",
        "\n",
        "# Create random sample\n",
        "df_final_labeling_set = df_raw.sample(\n",
        "    n=Intervention_sample_size,\n",
        ").reset_index(drop=True)\n",
        "\n",
        "print(f\"Random sample size: {len(df_final_labeling_set)}\")\n",
        "\n",
        "# Create an empty column for manual annotation\n",
        "df_final_labeling_set['intervention_label'] = ''"
      ],
      "metadata": {
        "id": "MYw9A8PhUgRb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "397b5545-e36c-47de-e221-95c4c085bcf6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random sample size: 1500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YURU7iNQKxmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Columns to keep (this was done to remove extra columns not needed for the labeling process)\n",
        "columns_for_labeling = ['speech_id','intervention_id','party','speaker_name','text','text_length','intervention_label']\n",
        "\n",
        "# Create a copy with only these columns\n",
        "df_final_labeling_set_reduced = df_final_labeling_set[columns_for_labeling].copy()"
      ],
      "metadata": {
        "id": "kvegHtgZKyTp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final Output for Manual Labeling"
      ],
      "metadata": {
        "id": "kV704tAzElD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save sample\n",
        "output_path = '/content/drive/MyDrive/Thesis/intervention_sample_for_manual_labeling.xlsx'\n",
        "df_final_labeling_set_reduced.to_csv(output_path, index=False, encoding='utf-8')\n",
        "\n",
        "print(f\"\\nSample created for manual labeling: {len(df_final_labeling_set_reduced)} interventions.\")\n",
        "print(f\"\\nRandom sample is saved to: {output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFV_sw4kiWUZ",
        "outputId": "d3750391-c273-42b4-97ab-110101533915"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample created for manual labeling: 1500 interventions.\n",
            "\n",
            "Random sample is saved to: /content/drive/MyDrive/Thesis/intervention_sample_for_manual_labeling.xlsx\n"
          ]
        }
      ]
    }
  ]
}